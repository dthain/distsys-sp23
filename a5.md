---
layout: default
title: A5 - Concurrency
---

# A5 - Concurrency

## Overview

A responsive service must be able to deal with multiple clients at once.
In this assignment, you will modify your server to accept multiple
connections and interleave their requests.

## Event Driven Server

In class, we discussed several models for building servers:
single-threaded (what you have already), multi-threaded,
multi-process, and event-driven.  We are going to use the latter
model, because all operations must share the same underlying
checkpoint and transaction log.

Here is how to think about it:

Your server will keep track of the master socket on which it is listening
for new connections.  It will also have a **dictionary** of sockets, each one
representing a currently-connected client.  In the server's main loop, it
should use `select` to determine which socket is readable.
If the master socket is ready for reading, then the server should accept a new connection
and add it to the set.  If any other socket is ready for reading, then the
server should read a request from the socket, perform the action, send a response,
and then go back to waiting.

This approach strikes a balance between concurrency and complexity.
The server can handle multiple clients connected at once, and can interleave
multiple requests to satisfy all comers.  Each request still executes one
at a time, so we say that the request stream is **serialized**.  You won't
get the performance benefit of running multiple processes/threads concurrently,
but you won't have the synchronization problems from that either.
(We will make up for that later by running multiple servers concurrently.)

Be sure to test your server carefully before moving on.  Try various combinations
of clients connecting and leaving, and ensure that the server does not crash,
no matter when or how the clients connect and disconnect.  Add some debugging
output to assure yourself that the server is in fact interleaving requests from multiple
clients.

## Testing and Measurement

Evaluate the performance of your service in the presence of mulitple clients, as follows.
Start a single instance of your server on one of the student machines.
Then, on a **different** student machine, run a single instance of the `TestPerf.py` program.

```
python TestPerf.py YOURNETID-a5
```

Capture the output of that test, then run two clients **simultaneously**:

```
python TestPerf.py YOURNETID-a5 & python TestPerf.py YOURNETID-a5 & wait
```

And continue in this way until the performance "levels out".  Hint: Look at the sum of the throughputs obtained by simultaneous clients.

## What to Turn In

Please review the [general instructions](general) for submitting assignments.

Turn in all of your source code, along with a lab report titled `REPORT` that describes the following in detail:
- The *raw data* from your throughput measurements, all laid out in a nice tabular form. (Plain text is fine.)
- Consider your performance data closely, and explain what what it tells you about the system as a whole.  Take your time to look at the data from multiple perspectives: consider individual clients, and the sum of simultaneous clients; consider differences between operation types; consider what happens as the number of clients increase. 
